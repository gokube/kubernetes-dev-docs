# 目录

<!-- TOC -->

- [目录](#目录)
- [Get 后 Update K8S 对象时，可能会失败，较好的实践方式是使用 client-go 提供的 retry 工具函数](#get-后-update-k8s-对象时可能会失败较好的实践方式是使用-client-go-提供的-retry-工具函数)
- [开发自定义 Controller 时，为何一般使用 workqueue?](#开发自定义-controller-时为何一般使用-workqueue)
- [开发自定义 Controller 时，对资源类型的删除回调函数，为何一般不用 workqueue 来处理？](#开发自定义-controller-时对资源类型的删除回调函数为何一般不用-workqueue-来处理)
- [创建 Index 和 DeltaFIFO 的 KeyFunc 为何不同？](#创建-index-和-deltafifo-的-keyfunc-为何不同)
- [自定义 Controller 的 OnDelete Handler 为何要判断对象类型是否是 DeletedFinalStateUnknownn 类型？](#自定义-controller-的-ondelete-handler-为何要判断对象类型是否是-deletedfinalstateunknownn-类型)
- [为何要在调用了 InformerFactory()的 Informer() 方法后，才调用它的 Run() 方法？](#为何要在调用了-informerfactory的-informer-方法后才调用它的-run-方法)
- [为何要等所有 Informer 的 WaitSync 都返回后，再执行 workqueue 的 worker goroutine？](#为何要等所有-informer-的-waitsync-都返回后再执行-workqueue-的-worker-goroutine)
- [如果 pkg/apis/<group>/<versin>/register.go 中没有将自定义 CRD 类型添加到 scheme.AddKnownTypes 中，则创建 Core Group 中的资源对象时出错](#如果-pkgapisgroupversinregistergo-中没有将自定义-crd-类型添加到-schemeaddknowntypes-中则创建-core-group-中的资源对象时出错)
- [启用 client-go 中的日志](#启用-client-go-中的日志)
- [添加自定义类型的步骤](#添加自定义类型的步骤)
- [CRD Kind 冲突 Bug](#crd-kind-冲突-bug)
- [自定义资源对象的名称不能和 K8S 已有的重名](#自定义资源对象的名称不能和-k8s-已有的重名)
- [给对象打 Path 的方法](#给对象打-path-的方法)
- [K8S Job 的 .spec.selector 和 .spec.template 是不能更新的](#k8s-job-的-specselector-和-spectemplate-是不能更新的)

<!-- /TOC -->

# Get 后 Update K8S 对象时，可能会失败，较好的实践方式是使用 client-go 提供的 retry 工具函数

``` go
// 来源于：k8s.io/client-go/examples/create-update-delete-deployment/main.go
	//    You have two options to Update() this Deployment:
	//
	//    1. Modify the "deployment" variable and call: Update(deployment).
	//       This works like the "kubectl replace" command and it overwrites/loses changes
	//       made by other clients between you Create() and Update() the object.
	//    2. Modify the "result" returned by Get() and retry Update(result) until
	//       you no longer get a conflict error. This way, you can preserve changes made
	//       by other clients between Create() and Update(). This is implemented below
	//			 using the retry utility package included with client-go. (RECOMMENDED)
	//
	// More Info:
	// https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency

	retryErr := retry.RetryOnConflict(retry.DefaultRetry, func() error {
		// Retrieve the latest version of Deployment before attempting update
		// RetryOnConflict uses exponential backoff to avoid exhausting the apiserver
		result, getErr := deploymentsClient.Get("demo-deployment", metav1.GetOptions{})
		if getErr != nil {
			panic(fmt.Errorf("Failed to get latest version of Deployment: %v", getErr))
		}

		result.Spec.Replicas = int32Ptr(1)                           // reduce replica count
		result.Spec.Template.Spec.Containers[0].Image = "nginx:1.13" // change nginx version
		_, updateErr := deploymentsClient.Update(result)
		return updateErr
	})
	if retryErr != nil {
		panic(fmt.Errorf("Update failed: %v", retryErr))
	}
	fmt.Println("Updated deployment...")
```

# 开发自定义 Controller 时，为何一般使用 workqueue?
# 开发自定义 Controller 时，对资源类型的删除回调函数，为何一般不用 workqueue 来处理？

因为 Informer 内部使用的 controller 会先将对象从 ClientState Indexer 缓存中删除，再调用用户配置的回调函数。
所以，如果将对象 Key 入 workqueue 后，worker 使用 Key 从 Lister 会查不到对象。

# 创建 Index 和 DeltaFIFO 的 KeyFunc 为何不同？

``` go
clientState := NewIndexer(DeletionHandlingMetaNamespaceKeyFunc, indexers)
fifo := NewDeltaFIFO(MetaNamespaceKeyFunc, clientState)
```

因为 DeltaFIFO 接收的是从 apiserver List/Watch 的 K8S 资源对象，所以可以用 MetaNamespaceKeyFunc 提取它的 NS 和 Name。

但是 NewIndexer() 返回的 clientState 一般是 Reflector 从 DeltaFIFO 弹出的 Deltas，它是一个 Delta 的列表，而 Delta.Object 可能是 K8S 资源对象，也可能是 DeletedFinalStateUnknown。所以 NewIndexer() 使用能区分这两种类型的 DeletionHandlingMetaNamespaceKeyFunc KeyFunc。

# 自定义 Controller 的 OnDelete Handler 为何要判断对象类型是否是 DeletedFinalStateUnknownn 类型？

``` go
// 来源于：https://github.com/kubernetes/sample-controller/blob/master/controller.go
func (c *Controller) handleObject(obj interface{}) {
	var object metav1.Object
	var ok bool
	// 判断是原始对象还是 DeletedFinalStateUnknown 对象
	if object, ok = obj.(metav1.Object); !ok {
		tombstone, ok := obj.(cache.DeletedFinalStateUnknown)
		if !ok {
			utilruntime.HandleError(fmt.Errorf("error decoding object, invalid type"))
			return
		}
		// 从 DeletedFinalStateUnknown 对象中提取实际对象
		object, ok = tombstone.Obj.(metav1.Object)
		if !ok {
			utilruntime.HandleError(fmt.Errorf("error decoding object tombstone, invalid type"))
			return
		}
		klog.V(4).Infof("Recovered deleted object '%s' from tombstone", object.GetName())
	}
	klog.V(4).Infof("Processing object: %s", object.GetName())
	...
}
```

DeltaFIFO  Watch apiserver 过程中可能因网络等问题出现丢事件的情况，如果丢失了 Delete 事件，则后续 Reflector 重复执行 `ListAndWatch()` 方法从 apiserver 获取的对象集合 set1 会出现与 knownObjects 对象集合 set2 不一致的情况。
为了保证两者一致，DeltaFIFO 的 `Replace()` 方法将位于 set1 但不在 set2 中的对象用 `DeletedFinalStateUnknown` 类型对象封装，再保存到 Delta.Object 中。
而上面 handlerObject() 的参数即为 Delta.Object。

# 为何要在调用了 InformerFactory()的 Informer() 方法后，才调用它的 Run() 方法？

# 为何要等所有 Informer 的 WaitSync 都返回后，再执行 workqueue 的 worker goroutine？

在开发 K8S Controller 的时候，一个惯例是调用 cache.WaitForCacheSync，等待所有 Informer Cache 都同步后才启动消费 workqueue 的 worker：

``` go
// 来源于：https://github.com/kubernetes/sample-controller/blob/master/controller.go

// 自定义的 Controller
type Controller struct {
	...
	deploymentsLister appslisters.DeploymentLister
	deploymentsSynced cache.InformerSynced  // InformerSynced 函数类型
	...
}

func NewController(
	kubeclientset kubernetes.Interface,
	sampleclientset clientset.Interface,
	deploymentInformer appsinformers.DeploymentInformer,
	fooInformer informers.FooInformer) *Controller {
		...
		controller := &Controller{
			kubeclientset:     kubeclientset,
			sampleclientset:   sampleclientset,
			deploymentsLister: deploymentInformer.Lister(),
			deploymentsSynced: deploymentInformer.Informer().HasSynced, // Infomer 的 HasSynced() 方法
		}
		...
}

// 等待所有类型的 Informer 的 HasSynced() 方法返回为 true 时再启动 workers
func (c *Controller) Run(threadiness int, stopCh <-chan struct{}) error {
	...
	// Wait for the caches to be synced before starting workers
	klog.Info("Waiting for informer caches to sync")
	if ok := cache.WaitForCacheSync(stopCh, c.deploymentsSynced, c.foosSynced); !ok {
		return fmt.Errorf("failed to wait for caches to sync")
	}

	klog.Info("Starting workers")
	// Launch two workers to process Foo resources
	for i := 0; i < threadiness; i++ {
		go wait.Until(c.runWorker, time.Second, stopCh)
	}
	...
}
```

为何要等各 informer 的 HasSynced() 返回为 true 时才开始启动 worker 呢？

因为 HasSynced() 返回 true 时表明 Reflecter List 的第一批对象都从 DeltaFIFO 弹出，并由 controller **更新到 clientState 缓存中，这样 worker 才能通过通过对象名称（Key）从 Lister Get 到对象**。否则对象可能还在 DeltaFIFO 中且没有同步到 clientState 缓存中，这样 worker 通过对象名称从 Lister 中 Get 不到对象。

# 如果 pkg/apis/<group>/<versin>/register.go 中没有将自定义 CRD 类型添加到 scheme.AddKnownTypes 中，则创建 Core Group 中的资源对象时出错

创建 AolPod 的语句：

``` go
func newAolPod(pod *coreV1.Pod) *aolV1alpha1.AolPod {
        labels := pod.ObjectMeta.Labels
        labels["controller"] = pod.ObjectMeta.Name
        labels["pod.aol.4pd.io"] = pod.ObjectMeta.Name
        labels["aol.4pd.io"] = "true"

        return &aolV1alpha1.AolPod{
                ObjectMeta: metav1.ObjectMeta{
                        Name:      pod.ObjectMeta.Name,
                        Namespace: pod.ObjectMeta.Namespace,
                        OwnerReferences: []metav1.OwnerReference{
                                *metav1.NewControllerRef(pod, schema.GroupVersionKind{
                                        Group:   aolV1alpha1.SchemeGroupVersion.Group,
                                        Version: aolV1alpha1.SchemeGroupVersion.Version,
                                        Kind:    "Pod",
                                }),
                        },
                        Labels: labels,
                },
                Spec:   pod.Spec,
                Status: pod.Status,
        }
}
```

后续创建：

``` go
aolPod, err := c.aolPodLister.AolPods(pod.ObjectMeta.Namespace).Get(podName)
if errors.IsNotFound(err) {
				aolPod, err = c.aolclientset.AolV1alpha1().AolPods(pod.ObjectMeta.Namespace).Create(newAolPod(pod))
}
if err != nil {
				fmt.Printf("---> create failed: %#v\n", newAolPod(pod))
				return err
}
```
失败日志：

``` txt
---> create failed: &v1alpha1.AolPod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"my-aol-deploy-7996d57dfd-lqmtp", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"controller":"my-aol-deploy-7996d57dfd-lqmtp", "deploy.aol.4pd.io":"my-aol-deploy", "pod-template-hash":"3552813898", "run":"my-aol-nginx", "pod.aol.4pd.io":"my-aol-deploy-7996d57dfd-lqmtp", "aol.4pd.io":"true"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"aol.4pd.io/v1alpha1", Kind:"Pod", Name:"my-aol-deploy-7996d57dfd-lqmtp", UID:"39242763-350f-11e9-b4fd-0cc47a2a835a", Controller:(*bool)(0xc000c1be49), BlockOwnerDeletion:(*bool)(0xc000c1be48)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"aol-deploy-configmap", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc0006168c0), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}, v1.Volume{Name:"aol-deploy-secret", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc000616980), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}, v1.Volume{Name:"default-token-86q99", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0006169c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"nginx", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort{v1.ContainerPort{Name:"", HostPort:0, ContainerPort:80, Protocol:"TCP", HostIP:""}}, EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"CONFIGMAP", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc000afd0c0)}, v1.EnvVar{Name:"SESCRET", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc000afd100)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:100, scale:6}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100M", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:100, scale:6}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100M", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"aol-deploy-configmap", ReadOnly:false, MountPath:"/etc/configmap", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}, v1.VolumeMount{Name:"aol-deploy-secret", ReadOnly:false, MountPath:"/etc/secret", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}, v1.VolumeMount{Name:"default-token-86q99", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"Always", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, Std
inOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0004661d0), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"m7-power-k8s01", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0005b1560), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686264311, loc:(*time.Location)(0x1fc55e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"", PodIP:"", StartTime:(*v1.Time)(nil), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus(nil), QOSClass:"Guaranteed"}}
```

解决办法：将自定义类型添加到 scheme.AddKnownTypes 中；

# 启用 client-go 中的日志

``` go
flagset := flag.NewFlagSet("klog", flag.ExitOnError)
flagset.Set("logtostderr", "true")
flagset.Set("v", "4")
klog.InitFlags(flagset)
```

# 添加自定义类型的步骤

1. 在 `pkg/apis/` 目录下添加自定义资源类型的 <group/version> 两级子目录，子目录中添加三个 go 文件，如：

	``` text
		pkg/
			apis/
				aol/
					v1alpha1/
						doc.go
						register.go
						types.go
	```

2. 修改 register.go 文件中的常量 GroupName 和 SchemeGroupVersion 变量的 Version，与实际情况一致，如：

	``` go
	// GroupName is the group name use in this package
	const GroupName = "aol.4pd.io"

	// SchemeGroupVersion is group version used to register these objects
	var SchemeGroupVersion = schema.GroupVersion{Group: GroupName, Version: "v1alpha1"}
	```

3. 如果 <group> 目录与上面定义的 GroupName 不一致，则需要在 doc.go 文件中添加 +groupName 注释：

	``` go
	// 来源于：pkg/apis/aol/v1alpha1/doc.go

	// +k8s:deepcopy-gen=package
	// +k8s:openapi-gen=true
	// +groupName=aol.4pd.io

	package v1alpha1
	```
	+ 上面的 `+k8s:deepcopy-gen=package` 注释也是必须的，否则不会为 `types.go` 中的各 go struct 类型创建 DeepCopy 方法；

	否则，后续自动生成的 fake clientset 的 Group 不对，如：
	``` go
	// 未添加 +groupName 注释时，自动生成的 Group: "aol" 为 <group> 目录名称
	// 来源于：pkg/client/clientset/versioned/typed/aol/v1alpha1/fake/fake_aoldeployment.go
	var aoldeploymentsResource = schema.GroupVersionResource{Group: "aol", Version: "v1alpha1", Resource: "aoldeployments"}
	```

	使用这个错误的 fake clientset 会引起单元测试失败：

	``` text
	E0219 17:02:08.771250   80977 reflector.go:134] gitlab.4pd.io/pht3/aol/pkg/client/informers/externalversions/factory.go:117: Failed to list *v1alpha1.AolDeployment: no kind "AolDeploymentList" is registered for version "aol/v1alpha1" in scheme "gitlab.4pd.io/pht3/aol/pkg/client/clientset/versioned/fake/register.go:30"

4. 在 `types.go` 文件中添加自定义类型的 `go struct` 定义，参考：[Kubernetes Deep Dive: Code Generation for CustomResources](https://blog.openshift.com/kubernetes-deep-dive-code-generation-customresources/)
5. 将自定义类型加到 `pkg/apis/aol/v1alpha1/register.go` 的 `addKnownTypes` 列表中；
6. 安装 code-generator 命令行工具：
  ``` go
	cd $GOPATH/src/k8s.io
	git clone https://github.com/kubernetes/code-generator.git
	go install code-generator/cmd/...
	export PATH=$GOPATH/bin:$PATH
	```
7. 执行 `hack/update-codegen.sh` 脚本，为自定义类型生成 `DeepCopyObject()` 方法定义（位于 pkg/apis/aol/v1alpha1/zz_generated.deepcopy.go 文件中）和 `client` (位于 pkg/client 各子目录下)；

# CRD Kind 冲突 Bug

``` bash
[root@m7-power-k8s01 ~]# ETCDCTL_API=3 etcdctl     --endpoints=${ETCD_ENDPOINTS}     --cacert=/opt/k8s/work/ca.pem     --cert=/opt/k8s/work/etcd
.pem     --key=/opt/k8s/work/etcd-key.pem     get /registry/ --prefix --keys-only|grep aol
/registry/apiextensions.k8s.io/customresourcedefinitions/aoldeployments.aol.4pd.io
/registry/apiregistration.k8s.io/apiservices/v1alpha1.aol.4pd.io
/registry/events/default/my-aol-deploy-566c9889b8-59dln.157cb613778bf01d
/registry/events/default/my-aol-deploy-566c9889b8-59dln.157cb613a468c8f0
/registry/events/default/my-aol-deploy-566c9889b8-59dln.157cb6148930c78a
/registry/events/default/my-aol-deploy-566c9889b8-59dln.157cb6148b273cf9


[root@m7-power-k8s01 ~]# ETCDCTL_API=3 etcdctl     --endpoints=${ETCD_ENDPOINTS}     --cacert=/opt/k8s/work/ca.pem     --cert=/opt/k8s/work/etcd.pem     --key=/opt/k8s/work/etcd-key.pem     del /registry/apiextensions.k8s.io/customresourcedefinitions/aoldeployments.aol.4pd.io
[root@m7-power-k8s01 ~]# ETCDCTL_API=3 etcdctl     --endpoints=${ETCD_ENDPOINTS}     --cacert=/opt/k8s/work/ca.pem     --cert=/opt/k8s/work/etcd
.pem     --key=/opt/k8s/work/etcd-key.pem     del /registry/apiregistration.k8s.io/apiservices/v1alpha1.aol.4pd.io
0
```

# 自定义资源对象的名称不能和 K8S 已有的重名

``` bash
[root@m7-power-k8s02 examples]# cat aol-deploy-crd.yaml
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: deployments.aol.4pd.io
spec:
  group: aol.4pd.io
  version: v1alpha1
  names:
    kind: AolDeploy
    plural: aoldeploys
    singular: aoldeploy
    shortNames:
    - adeploy
  scope: Namespaced
  subresources:
    status: {}

[root@m7-power-k8s02 examples]# kubectl apply -f aol-deploy-crd.yaml
The CustomResourceDefinition "deployments.aol.4pd.io" is invalid: metadata.name: Invalid value: "deployments.aol.4pd.io": must be spec.names.plural+"."+spec.group

I0124 11:40:25.316703   31235 reflector.go:169] Listing and watching *v1alpha1.Deployment from gitlab.4pd.io/pht3/aol/pkg/client/informers/externalversions/factory.go:117
E0124 11:40:25.318620   31235 reflector.go:134] gitlab.4pd.io/pht3/aol/pkg/client/informers/externalversions/factory.go:117: Failed to list *v1alpha1.Deployment: the server could not find the requested resource (get deployments.aol.4pd.io)
```

# 给对象打 Path 的方法

1. 命令行：

	``` bash
	kubectl patch deploy xxx -n default --type=json -p='[{"op":"remove", "path":"/metadata/finalizers/0"}]'
	```

2. 简单编写 Patch：

	``` go
	deletePolicy := metav1.DeletePropagationForeground
	deleteOptions := metav1.DeleteOptions{
					PropagationPolicy: &deletePolicy,
	}
	listOptions := metav1.ListOptions{
					LabelSelector: fmt.Sprintf("controller=%s", object.GetName()),
	}
	if list, err := c.kubeclientset.ExtensionsV1beta1().Deployments(object.GetNamespace()).List(listOptions); err != nil {
					utilruntime.HandleError(err)
					return
	} else {
		for _, deploy := range list.Items {
			if err := c.kubeclientset.ExtensionsV1beta1().Deployments(object.GetNamespace()).Delete(deploy.GetName(), &deleteOptions); err != nil {
					utilruntime.HandleError(err)
					return
			}
			if dep, err := c.kubeclientset.ExtensionsV1beta1().Deployments(object.GetNamespace()).Patch(
					deploy.GetName(), 
					types.JSONPatchType, 
					[]byte(fmt.Sprintf(`[{"op": "remove", "path": "/metadata/finalizerz"}]`))); err != nil {
							utilruntime.HandleError(err)
							return
			}
		}
	}
	```

3. 复杂的 Patch：

``` go
// 参考值：
// 1. https://github.com/tamalsaha/patch-demo/blob/master/main.go
// 2. https://github.com/kubernetes/client-go/issues/236
// 创建一个 Deploy
ko, err = kubeClient.AppsV1beta1().Deployments(ko.Namespace).Create(ko)
if err != nil {
	log.Fatalln(err)
}

	// 将该 Deploy JSON 编码
oJson, err := json.Marshal(ko)
if err != nil {
	log.Fatalln(err)
}

	// 修改 Deploy 的内容
if ko.Annotations == nil {
	ko.Annotations = map[string]string{}
}
ko.Annotations["example.com"] = "123"
ko.Spec.Replicas = gt.Int32P(2)
ko.Spec.Template.Spec.Containers = append(ko.Spec.Template.Spec.Containers, apiv1.Container{
	Name:            "bnew",
	Image:           "busybox",
	ImagePullPolicy: apiv1.PullIfNotPresent,
	Command: []string{
		"sleep",
		"3600",
	},
	VolumeMounts: []apiv1.VolumeMount{
		{
			Name:      TestSourceDataVolumeName,
			MountPath: TestSourceDataMountPath,
		},
	},
})
	// 将修改后的 Deploy JSON 编码
mJson, err := json.Marshal(ko)
if err != nil {
	log.Fatalln(err)
}

	// 获取两个 JSON 的差别
patch, err := jsonpatch.CreatePatch(oJson, mJson)
if err != nil {
	log.Fatalln(err)
}
pb, err := json.MarshalIndent(patch, "", "  ")
if err != nil {
	log.Fatalln(err)
}
fmt.Println(string(pb))

	// 发送 Patch 请求
final, err := kubeClient.AppsV1beta1().Deployments(ko.Namespace).Patch(ko.Name, types.JSONPatchType, pb)
if err != nil {
	log.Fatalln(err)
}

fb, err := json.MarshalIndent(final, "", "  ")
if err != nil {
	log.Fatalln(err)
}
fmt.Println(string(fb))
```

#  K8S Job 的 .spec.selector 和 .spec.template 是不能更新的

如果更新 K8S Job 的 .spec.template 如 image，就会出错：

``` text
Job.batch "aol-test" is invalid: spec.template: Invalid value: xxx: field is immutable
```

各 K8S 资源类型不可更新的字段，可以参考：https://github.com/pulumi/pulumi-kubernetes/blob/master/pkg/provider/diff.go